version: 2
jobs:
  build:
    docker:
      - image: circleci/python:3.7.2

    working_directory: ~/repo
    steps:
      - run:
          name: Install base apt packages
          command: |
            sudo apt-get update --yes -qq
            sudo apt-get install --yes -qq git-crypt jq golang-go
      - checkout
      - run:
          name: Pull Submodules
          command: |
            git submodule init
            git submodule update --remote
      - restore_cache:
          keys:
          - v2-dependencies-{{ checksum "requirements.txt" }}
          # fallback to using the latest cache if no exact match is found
          - v2-dependencies-
      - run:
          name: install dependencies
          command: |
            python3 --version
            python3 -m venv venv
            source venv/bin/activate
            pip install --upgrade -r requirements.txt

            curl -sSL https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-226.0.0-linux-x86_64.tar.gz | tar -C venv/ -xzf -
            echo 'export PATH="${HOME}/repo/venv/bin:${HOME}/repo/venv/google-cloud-sdk/bin:${PATH}"' >> ${BASH_ENV}

      - setup_remote_docker
      - save_cache:
          paths:
            - ./venv
          key: v2-dependencies-{{ checksum "requirements.txt" }}
      - run:
          name: Determine range of commits we are building
          command: |
              # CircleCI doesn't have equivalent to Travis' COMMIT_RANGE
              COMMIT_RANGE=$(./.circleci/get-commit-range.py)
              echo ${COMMIT_RANGE}
              echo "export COMMIT_RANGE='${COMMIT_RANGE}'" >> ${BASH_ENV}

      - run:
          name: Test building gcp-uscentral1b.pangeo.io image if needed
          when: always
          no_output_timeout: 2h
          command: |
            hubploy build gcp-uscentral1b --commit-range ${COMMIT_RANGE}

      - run:
          name: Test building aws-uswest2.pangeo.io image if needed
          when: always
          command: |
            hubploy build icesat2 --commit-range ${COMMIT_RANGE}
          environment:
            PYTHONIOENCODING: utf-8

      # This is currently disabled becauses it always runs and because the Azure
      # container registry is not open to annonymous read access. This can be changed
      # but it will take some changes to our Azure account to allow this feature in
      # preview mode.
      #- run:
      #    name: Test building ooi.pangeo.io image if needed
      #    when: always
      #    command: |
      #      hubploy build ooi --commit-range ${COMMIT_RANGE}
      #    environment:
      #      PYTHONIOENCODING: utf-8

  deploy:
    docker:
      - image: circleci/python:3.7.2
    working_directory: ~/repo
    steps:
      - run:
          name: Install base apt packages
          command: |
            sudo apt-get update -qq --yes
            sudo apt-get install -qq --yes git-crypt golang-go
      - checkout
      # Download and cache dependencies
      - run:
          name: Pull Submodules
          command: |
            git submodule init
            git submodule update --remote
      - restore_cache:
          keys:
          - v2-dependencies-gcloud-226-{{ checksum "requirements.txt" }}
          # fallback to using the latest cache if no exact match is found
          - v2-dependencies-gcloud-226-

      - run:
          name: install dependencies
          command: |
            python3 -m venv venv
            source venv/bin/activate
            pip install --upgrade -r requirements.txt

            curl -sSL https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-226.0.0-linux-x86_64.tar.gz | tar -C venv/ -xzf -
            # https://github.com/awslabs/amazon-ecr-credential-helper/issues/101
            # Can simplify to sudo apt install amazon-ecr-credential-helper if running Ubuntu 19.04 and newer
            export GOPATH=$PWD/venv
            go get -u github.com/awslabs/amazon-ecr-credential-helper/ecr-login/cli/docker-credential-ecr-login

            # Be careful with quote ordering here. ${PATH} must not be expanded
            # Don't use ~ here - bash can interpret PATHs containing ~, but most other things can't.
            # Always use full PATHs in PATH!
            echo 'export PATH="${HOME}/repo/venv/bin:${HOME}/repo/venv/google-cloud-sdk/bin:${PATH}"' >> ${BASH_ENV}

      - setup_remote_docker

      - save_cache:
          paths:
            - ./venv
          key: v2-dependencies-gcloud-226-{{ checksum "requirements.txt" }}

      - run:
          name: Unlock default secrets
          command: |
            echo "${GIT_CRYPT_KEY}" | base64 -d > ~/repo/default.key
            git crypt unlock ~/repo/default.key
            rm ~/repo/default.key

      - run:
          name: Unlock ooi secrets
          command: |
            echo "${OOI_GIT_CRYPT_KEY}" | base64 -d > ~/repo/ooi.key
            git crypt unlock ~/repo/ooi.key
            rm ~/repo/ooi.key

      - run:
          name: Build gcp-uscentral1b.pangeo.io image if needed
          when: always
          no_output_timeout: 2h
          command: |
            hubploy build gcp-uscentral1b --check-registry --push

      - run:
          name: Build aws-uswest2.pangeo.io image if needed
          when: always
          command: |
            hubploy build icesat2 --check-registry --push
          environment:
            PYTHONIOENCODING: utf-8

      - run:
          name: Build ooi.pangeo.io image if needed
          when: always
          no_output_timeout: 1200
          command: |
            hubploy build ooi --check-registry --push
          environment:
            PYTHONIOENCODING: utf-8


      - run:
          name: Install helm
          when: always
          command: |
            curl https://get.helm.sh/helm-v3.1.2-linux-amd64.tar.gz | \
              tar -xzf -
            sudo mv linux-amd64/helm /usr/local/bin
            helm version
            helm repo add dask https://helm.dask.org/
            helm repo add jupyterhub https://jupyterhub.github.io/helm-chart/
            helm repo add dask-gateway https://dask.org/dask-gateway-helm-repo/
            helm repo add stable https://kubernetes-charts.storage.googleapis.com
            helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
            helm repo add prometheus-operator https://kubernetes-charts.storage.googleapis.com
            helm repo update

      - run:
          name: Deploy gcp-uscentral1b.pangeo.io
          when: always
          command: |
            hubploy deploy gcp-uscentral1b pangeo-deploy ${CIRCLE_BRANCH} --cleanup-on-fail --namespace ${CIRCLE_BRANCH}


      # NOTE: should move the dynamic IP into hubploy where credentials and awscli version already dealt with
      # sleep 2min for now, but better to poll for readiness https://docs.aws.amazon.com/eks/latest/userguide/cluster-endpoint.html
      - run:
          name: Add Runner IP to EKS Kubernetes API Whitelist
          when: always
          command: |
            export AWS_SHARED_CREDENTIALS_FILE=./deployments/icesat2/secrets/aws-config.txt
            RUNNERIP=`curl --silent https://checkip.amazonaws.com`
            aws --version
            aws eks update-cluster-config --region us-west-2 --name pangeo --resources-vpc-config publicAccessCidrs=${RUNNERIP}/32 > /dev/null
            sleep 120
      - run:
          name: Deploy aws-uswest2.pangeo.io
          when: always
          no_output_timeout: 1200
          command: |
            hubploy deploy icesat2 pangeo-deploy ${CIRCLE_BRANCH} --timeout 1200s --cleanup-on-fail

      - run:
          name: Revert to Original EKS IP Whitelist
          when: always
          command: |
            export AWS_SHARED_CREDENTIALS_FILE=./deployments/icesat2/secrets/aws-config.txt
            aws eks update-cluster-config --region us-west-2 --name pangeo --resources-vpc-config publicAccessCidrs=${AWS_IP_WHITELIST} > /dev/null

      - run:
          name: Deploy ooi.pangeo.io
          when: always
          no_output_timeout: 1200
          command: |
            hubploy deploy ooi pangeo-deploy ${CIRCLE_BRANCH} --timeout 1200s --cleanup-on-fail

  test:
    docker:
      - image: circleci/python:3.7.2

    working_directory: ~/repo
    steps:
      - run:
          name: Test gcp-uscentral1b.pangeo.io
          when: always
          command: |
            # Start a JupyterHub server for ... a bot.
            # curl -X POST -H "Authorization: token <token>" "http://127.0.0.1:8081/hub/api/users/<user>/server"
            curl -X POST -H "Authorization: token ${JUPYTERHUB_TOKEN}" "${JUPYTERHUB_URL}/hub/api/users/${JUPYTERHUB_USER}/server"
            # Copy the test file
            kubectl -n ${CIRCLE_BRANCH} cp test.py jupyter-${JUPYTERHUB_USER}:/tmp/test.py
      - run:
          name: Run tests
          command: |
            # Run the tests
            kubectl -n staging exec jupyter-${JUPYTERHUB_USER} /srv/conda/envs/notebook/bin/pytest /tmp/test.py
pi/users/tomaugspurger/server"

      - run:
          name: Stop server for <...>
          when: always
          command: |
            # TODO: get the status code?
            curl -X DELETE -H "Authorization: token ${JUPYTERHUB_TOKEN}" "${JUPYTERHUB_URL}/hub/api/users/${JUPYTERHUB_USER}/server"

workflows:
  version: 2
  build-and-deploy:
    jobs:
      - build:
          filters:
            branches:
              ignore:
                - staging
                - prod
      - deploy:
          filters:
            branches:
              only:
                - staging
                - prod
      - test
